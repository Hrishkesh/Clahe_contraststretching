{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import dateutil.parser\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "#from IPython.display import Image, display\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tracker_data(csv_file, row):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    sleep_interval = np.array([int(x) for x in df.iloc[row][\"duration\"].replace('[', '').replace(']','').split(',')])\n",
    "    sleep_event = np.array([int(x) for x in df.iloc[row][\"value\"].replace('[', '').replace(']','').split(',')])\n",
    "    #c = [colors[i] for i in sleep_event]\n",
    "    sleep_begin = dateutil.parser.parse(df.iloc[row][\"start\"]) - timedelta(minutes=22)\n",
    "    sleep_end = sleep_begin + timedelta(seconds=int(sleep_interval.sum()))\n",
    "    sleep_duration = []\n",
    "    s = sleep_begin.replace(tzinfo=None)\n",
    "    timestamps = []\n",
    "    for dur in sleep_interval:\n",
    "        timestamps += [s.timestamp()]\n",
    "        s += timedelta(seconds=int(dur))\n",
    "    return sleep_interval, sleep_event, timestamps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(path, imageset):\n",
    "    images = sorted(glob.glob(path + '*.png'))\n",
    "    #print(datetime.utcfromtimestamp(int(os.path.getmtime(images[0]))))\n",
    "    #image_time_begin = datetime.utcfromtimestamp(int(os.path.getmtime(images[0]))) + timedelta(hours=1)\n",
    "    image_time_begin = datetime.datetime.strptime(path.split('/')[-2],'%Y-%m-%d-%Hh%Mm%Ss')\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "    fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows=False)\n",
    "\n",
    "    stats = []\n",
    "    if imageset == 'gray' or imageset == 'histogram':\n",
    "        for image in tqdm_notebook(images):\n",
    "            image = cv2.imread(image)\n",
    "            fgmask = fgbg.apply(image)\n",
    "            fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "            stats += [fgmask.sum()]\n",
    "        print(imageset)\n",
    "        print(path)\n",
    "        \n",
    "    if imageset == 'blur' or imageset == 'histogram_blur':\n",
    "        for image in tqdm_notebook(images):\n",
    "            image = cv2.imread(image)\n",
    "            blur = cv2.GaussianBlur(image, (5,5),-1)\n",
    "            fgmask = fgbg.apply(blur)\n",
    "            fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "            stats += [fgmask.sum()]\n",
    "        print(imageset)\n",
    "        print(path)\n",
    "    return stats, image_time_begin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interval, events, stamps = read_tracker_data('./sleep/sleep_raw.csv', 2)\n",
    "sleep_states = np.dstack((events,stamps)).squeeze()\n",
    "\n",
    "'''imagesets = {\n",
    "    'gray' : './sleep/2018-11-25-20h28m08s/',\n",
    "    'blur' : './sleep/2018-11-25-20h28m08s/',\n",
    "    'histogram' : './2018-11-25-20h28m08s/',\n",
    "    'histogram_blur' : './2018-11-25-20h28m08s/',\n",
    "}\n",
    "'''\n",
    "imagesets = OrderedDict(\n",
    "    [('gray', './sleep/2018-11-25-20h28m08s/'),\n",
    "    ('blur', './sleep/2018-11-25-20h28m08s/'),\n",
    "    ('histogram', './2018-11-25-20h28m08s/'),\n",
    "    ('histogram_blur', './2018-11-25-20h28m08s/')\n",
    "])\n",
    "\n",
    "chunk_sizes_to_eval = [0.5, 1, 3, 5, 10, 15]\n",
    "distance_tot = []\n",
    "states_tot =[]\n",
    "time_tot=[]\n",
    "for imageset, path in imagesets.items():\n",
    "    stats, image_time_begin = read_images(path, imageset)\n",
    "    distance_chunk = []\n",
    "    states_tot1 = []\n",
    "    time_tot1 = []\n",
    "    for eval_chunk_size in chunk_sizes_to_eval:\n",
    "        fps = 3\n",
    "        chunks_in_seconds = int(60 * eval_chunk_size)\n",
    "        chunks = fps * chunks_in_seconds\n",
    "        num_chunks = len(stats) // chunks\n",
    "        diffs = []\n",
    "        overlap = fps * 0\n",
    "        for chunk_index in(range(0, num_chunks)):\n",
    "            start = chunk_index * chunks\n",
    "            start = min(start, abs(chunk_index * chunks - overlap))\n",
    "            r = slice(start, start + chunks)\n",
    "            arr = np.array(stats[r])\n",
    "            diffs += [np.mean(np.array(stats[r]))]\n",
    "\n",
    "        diffs = np.array(diffs)\n",
    "        diffs = np.where(diffs > np.mean(diffs) * 0.5, 1, 2)\n",
    "        nx = np.array(range(len(diffs)))\n",
    "        offset = 3 * chunks_in_seconds\n",
    "        #time = [image_time_begin + timedelta(seconds=int(x * chunks_in_seconds + offset)) for x in nx + 1]\n",
    "        time = [int((image_time_begin + datetime.timedelta(seconds=int(x * chunks_in_seconds + offset))).timestamp()) for x in nx + 1]\n",
    "        states = []\n",
    "        duration = []\n",
    "        last = None\n",
    "        cnt = 0\n",
    "        for i, v in enumerate(diffs):\n",
    "            if v != last:\n",
    "                states += [v]\n",
    "\n",
    "                if last is not None:\n",
    "                    duration += [cnt * chunks / fps ]\n",
    "                    cnt = 0\n",
    "            cnt += 1\n",
    "            last = v\n",
    "\n",
    "            if i == len(diffs) - 1:\n",
    "                duration += [cnt * chunks / fps ]\n",
    "\n",
    "        states = np.array(states)\n",
    "        duration = np.array(duration)\n",
    "        s = image_time_begin + timedelta(seconds=offset)\n",
    "        time = []\n",
    "        for dur in duration:\n",
    "            time += [s]\n",
    "            s += timedelta(seconds=dur)\n",
    "\n",
    "        # process data for evaluation\n",
    "\n",
    "        motion_time = [round(x.timestamp()) for x in time]\n",
    "        motion_states = np.dstack((states,motion_time)).squeeze()\n",
    "\n",
    "        distance, _ = fastdtw(sleep_states, motion_states, dist=euclidean)\n",
    "        distance_chunk.append(distance)\n",
    "        states_tot1.append(states)\n",
    "        time_tot1.append(motion_time)\n",
    "    distance_tot.append(distance_chunk)\n",
    "    states_tot.append(states_tot1)\n",
    "    time_tot.append(time_tot1)\n",
    "        \n",
    "print(distance_tot)\n",
    "        # save dist, chunk_size, imageset in csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = [0.5, 1, 3, 5, 10, 15]\n",
    "for chunksizes in range(len(chunk_size)):\n",
    "    filenames = ['chunk(0.5)', 'chunk(1)', 'chunk(3)', 'chunk(5)','chunk(10)', 'chunk(15)']\n",
    "    column_names = ['Chunksize', 'Imageset', 'Distance']\n",
    "    data = pd.DataFrame(columns=column_names)\n",
    "    imageset = ['gray', 'gray_blur', 'histogram', 'histogram_blur']\n",
    "    for exp in range(len(imageset)):\n",
    "        data.loc[exp] = [chunk_size[chunksizes], str(imageset[exp]), distance_tot[exp][chunksizes]]\n",
    "        data.to_csv(filenames[chunksizes] + '.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk1 = pd.read_csv(path + '/chunk(0.5).csv')\n",
    "chunk2 = pd.read_csv(path + '/chunk(1).csv')\n",
    "chunk3 = pd.read_csv(path + '/chunk(3).csv')\n",
    "chunk4 = pd.read_csv(path + '/chunk(5).csv')\n",
    "chunk5 = pd.read_csv(path + '/chunk(10).csv')\n",
    "chunk6 = pd.read_csv(path + '/chunk(15).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = list(chunk1['Distance'])\n",
    "y2 = list(chunk2['Distance'])\n",
    "y3=  list(chunk3['Distance'])\n",
    "y4 = list(chunk4['Distance'])\n",
    "y5 = list(chunk5['Distance'])\n",
    "y6 = list(chunk6['Distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tot = [y1, y2, y3, y4, y5, y6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars=[]\n",
    "for bar in range(len(y1)):\n",
    "    bars.append([y1[bar], y2[bar], y3[bar], y4[bar], y5[bar], y6[bar]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = chunk1['Imageset']\n",
    "chunk_size = [0.5, 1, 3, 5, 10, 15]\n",
    "barwidth = 0.25\n",
    "r1 = [0, 1.5, 3.25, 4.75, 6.25, 7.75]\n",
    "r2 = [num + barwidth for num in r1]\n",
    "r3 = [num + barwidth for num in r2]\n",
    "r4 = [num + barwidth for num in r3]\n",
    "r5 = r1+r2+r3+r4\n",
    "bars_tot = bars[0]+bars[1]+bars[2]+bars[3]\n",
    "labels = [int(round(x)) for x in bars_tot]\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.bar(r1, bars[0], color = 'r', width = barwidth, edgecolor='white', label= 'gray')\n",
    "plt.bar(r2, bars[1], color = 'b', width = barwidth, edgecolor='white', label= 'gray_blur')\n",
    "plt.bar(r3, bars[2], color = 'g', width = barwidth, edgecolor='white', label= 'histogram')\n",
    "plt.bar(r4, bars[3], color = 'cyan', width = barwidth, edgecolor='white', label= 'histogram_blur')\n",
    "\n",
    "plt.xlabel('Experiment', fontweight= 'bold')\n",
    "plt.ylabel('Distance', fontweight = 'bold')\n",
    "plt.xticks([0.4, 1.9, 3.65, 5.15, 6.65, 8.15], ['chunk(0.5)', 'chunk(1)', 'chunk(3)', 'chunk(5)', 'chunk(10)', 'chunk(15)'])\n",
    "plt.legend()\n",
    "\n",
    "for i in range(len(r5)):\n",
    "    plt.text(x = r5[i]-0.05, y = bars_tot[i]+9500, s = labels[i], size = 9, rotation =90)\n",
    "\n",
    "#plt.savefig(\"/home/hrishkeshpattepu/Clahe_contraststretching/dataset2_test.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r+0.2 + barwidth for r in range(len(bars[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearning]",
   "language": "python",
   "name": "conda-env-deeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
